Okay, I will outline the key definitions, lemmas, remarks, ideas, and examples from your "Notes.pdf" lecture notes, chapter by chapter.

## Outline of "Notes.pdf"

Here's a breakdown of the key content:

### Chapter 1: Probability space

* **Core Idea:** To model and study a random experiment mathematically, we need a probability space, which is a triplet $(\Omega, \mathcal{F}, P)$[cite: 7]. This framework ensures the theory is coherent[cite: 13].

* **1.1 Sample space ($\Omega$)**
    * **Definition:** The set of all possible outcomes of a random experiment. Each element $\omega \in \Omega$ is a realization of the experiment[cite: 16, 17, 18].
    * **Examples (Examples 1.1):**
        * Tossing a coin: $\Omega_{C_1} = \{H, T\}$[cite: 19].
        * Tossing a coin twice: $\Omega_{C_2} = \{HH, HT, TH, TT\}$[cite: 20].
        * Tossing a coin infinitely many times: $\Omega_{C_\infty} = \{H,T\}^{\mathbb{N}}$ (sequences of H/T)[cite: 21].
        * Lifetime of a lightbulb: $\Omega_{S_1} = \mathbb{R}^+ = (0, \infty)$[cite: 22, 23].
        * Arrival times of customers at a queue: $\Omega_Q = \{\omega=(\omega_1, \omega_2, ...) | \omega_i \in \mathbb{R}^+, \omega_1 < \omega_2 < \dots \}$[cite: 24].
    * **Remark:** It's not always possible to explicitly define $\Omega$ if the model is too complex[cite: 26].

* **1.2 Subsets, Events and Event Space ($\mathcal{F}$)**
    * **Idea:** We want to assign probabilities to collections of outcomes (events)[cite: 29].
    * **1.2.1 Subsets of $\Omega$ and possible problems:**
        * **Concept:** Attributing a "measure" or "weight" to collections of outcomes[cite: 30].
        * **Definition 1.3 (Indicator function):** For an event $E \subset \Omega$, $1_E(\omega) = 1$ if $\omega \in E$ and $0$ if $\omega \notin E$[cite: 37].
        * **Examples 1.2 (Events):**
            * Tossing tails: $E = \{T\}$[cite: 35].
            * At least one head in two tosses: $F = \{HH, HT, TH\}$[cite: 36].
            * Lightbulb dies between time $\alpha$ and $\beta$: $A = (\alpha, \beta)$[cite: 35].
            * Proportion of heads converges to $p$: $G_p = \{\omega | \frac{1}{n}\sum_{i=1}^{n}1_{\{H\}}(\omega_i) \to p \}$[cite: 35].
        * **Examples 1.4 (Combination of events and indicator functions):** [cite: 39, 40]
            * Impossible event ($\emptyset$): $1_{\emptyset} = 0$.
            * Certain event ($\Omega$): $1_{\Omega} = 1$.
            * Complement ($F^c$): $1_{F^c} = 1 - 1_F$.
            * Intersection ($\cap F_n$): $1_{\cap F_n} = \prod 1_{F_n}$.
            * Union ($\cup F_n$): $1 - \prod (1 - 1_{F_n})$.
        * **Problem (Banach-Tarski paradox):** Illustrates that without rules, "cutting" and "reassembling" sets can lead to contradictions in volume/mass. This motivates the need for "measurable sets"[cite: 48, 49, 51].
        * **Examples 1.5 (Vitali set):** An example of a non-measurable set in $[0,1]$, showing that assigning a "mass" (length) to all subsets can lead to contradictions[cite: 54, 56, 57].
    * **1.2.2 Event and event space ($\mathcal{F}$):**
        * **Idea:** Define a class of sets (a $\sigma$-algebra) to which we can safely assign probabilities[cite: 66].
        * **If $\Omega$ is finite or countably infinite:** Usually take $\mathcal{F} = \mathcal{P}(\Omega)$ (the power set of $\Omega$)[cite: 69].
            * **Example 1.6:** For two coin tosses, $\mathcal{F} = \mathcal{P}(\{H,T\}^2)$, which has $2^4=16$ elements[cite: 70, 71].
        * **If $\Omega$ is uncountable:** Cannot take $\mathcal{P}(\Omega)$. We define a $\sigma$-algebra.
        * **Definition 1.7 ($\sigma$-algebra):** A collection $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ is a $\sigma$-algebra if:
            1.  $\emptyset \in \mathcal{F}$.
            2.  If $F \in \mathcal{F}$, then $F^c \in \mathcal{F}$.
            3.  If $(F_n : n \in \mathbb{N})$ is a sequence of sets in $\mathcal{F}$, then $\bigcup_{n \in \mathbb{N}} F_n \in \mathcal{F}$[cite: 72, 73].
            * **Implications:** $\Omega \in \mathcal{F}$, and $\mathcal{F}$ is closed under countable intersections[cite: 73, 74].
        * **Example 1.8:** For $E \subset \Omega$, $\mathcal{F} = \{\emptyset, E, E^c, \Omega\}$ is a $\sigma$-algebra[cite: 75, 76].
        * **Definition 1.9 ($\sigma$-algebra generated by $\mathcal{A}$):** $\sigma(\mathcal{A})$ is the smallest $\sigma$-algebra containing all sets in a collection $\mathcal{A}$[cite: 77].
        * **Example 1.10:** $\sigma(E) = \{\emptyset, E, E^c, \Omega\}$[cite: 78].
        * **Examples 1.11 (Important examples):** [cite: 79]
            * **Borel $\sigma$-algebra on $\mathbb{R}$ ($\mathcal{B}(\mathbb{R})$):** Generated by intervals like $(-\infty, x]$. It contains all relevant subsets of $\mathbb{R}$[cite: 80].
            * **Infinite coin tossing:** $\mathcal{F} = \sigma(F_n : n \in \mathbb{N})$ where $F_n$ is the event of heads on the $n$-th toss[cite: 80, 81].

* **1.3 Probability Measures ($\mathbb{P}$)**
    * **Definition 1.12 (Kolmogorov's axioms):** A map $\mathbb{P}: \mathcal{F} \to [0,1]$ is a probability measure if:
        1.  $\mathbb{P}(\Omega) = 1$.
        2.  $\sigma$-additivity: For any sequence of *disjoint* events $(F_n)$ in $\mathcal{F}$, $\mathbb{P}(\bigcup_{n \in \mathbb{N}} F_n) = \sum_{n \in \mathbb{N}} \mathbb{P}(F_n)$[cite: 81, 82].
        * **Consequence:** $\mathbb{P}(\emptyset) = 0$.
    * **Theorem 1.13 (Lebesgue, Borel):** Existence of a unique probability measure $\mathbb{P}$ on $([0,1], \mathcal{B}([0,1]))$ such that $\mathbb{P}([0,x])=x$ for all $x \in [0,1]$. This is the fundamental model (uniform distribution on $[0,1]$)[cite: 87, 88].
    * **Proposition 1.14 (Properties of $\mathbb{P}$):** [cite: 93]
        * $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$[cite: 93].
        * If $A \subseteq B$, then $\mathbb{P}(A) \le \mathbb{P}(B)$[cite: 94].
        * Finite additivity for disjoint events: $\mathbb{P}(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n \mathbb{P}(A_i)$[cite: 94].
        * Union bound (Boole's inequality): $\mathbb{P}(\bigcup_{i=1}^n A_i) \le \sum_{i=1}^n \mathbb{P}(A_i)$[cite: 94].
        * $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)$[cite: 94].
    * **Proposition 1.15 (Inclusion-Exclusion Principle):** General formula for the probability of a union of $n$ events[cite: 96].
    * **Proposition 1.16 (Continuity of $\mathbb{P}$):** [cite: 98]
        * Continuity from below: If $A_1 \subseteq A_2 \subseteq \dots$ and $A = \bigcup A_n$, then $\mathbb{P}(A_n) \uparrow \mathbb{P}(A)$[cite: 98, 99].
        * Continuity from above: If $B_1 \supseteq B_2 \supseteq \dots$ and $B = \bigcap B_n$, then $\mathbb{P}(B_n) \downarrow \mathbb{P}(B)$[cite: 99].
    * **Example 1.17:** Eventual extinction of a population, $A_n = \{\text{extinct by time n}\}$, $A_n \subseteq A_{n+1}$, so $\mathbb{P}(A_n) \uparrow \mathbb{P}(\text{eventual extinction})$[cite: 100, 101].
    * **Countable Union Bound:** $\mathbb{P}(\bigcup_{n=1}^\infty A_n) \le \sum_{n=1}^\infty \mathbb{P}(A_n)$[cite: 102].

### Chapter 2: Random Variables

* **Core Idea:** Observables from an experiment, mapping outcomes in $\Omega$ to real numbers[cite: 103, 105].
* **Definition 2.1 (Random Variable):** A mapping $X: \Omega \to \mathbb{R}$ such that $\{\omega \in \Omega : X(\omega) \le x\} \in \mathcal{F}$ for all $x \in \mathbb{R}$ (i.e., $X$ is $\mathcal{F}$-measurable)[cite: 108].
* **Remark 2.2:**
    * $X^{-1}(A) = \{X \in A\} \in \mathcal{F}$ for any Borel set $A \in \mathcal{B}(\mathbb{R})$[cite: 109].
    * Can extend to $X$ taking values in $\mathbb{R} \cup \{\pm\infty\}$[cite: 109].
    * Most functions encountered will be measurable[cite: 109].
* **Example 2.3:** For customer arrivals $\omega = (\omega_1, \omega_2, \dots)$, $T_1(\omega) = \omega_1$ (first arrival time) and $G_1(\omega) = \omega_2 - \omega_1$ (gap between first two arrivals) are random variables[cite: 110, 111].
* **Definition 2.4 (Distribution of $X$ and Distribution Function $F_X$):**
    * Distribution $\mathbb{P}_X(A) = \mathbb{P}(X \in A)$ for $A \in \mathcal{B}(\mathbb{R})$[cite: 113].
    * Distribution Function (CDF): $F_X(x) = \mathbb{P}(X \le x)$[cite: 114].
* **Properties of CDF $F_X$:** Increasing, right-continuous, $\lim_{x \to -\infty} F_X(x) = 0$, $\lim_{x \to \infty} F_X(x) = 1$[cite: 117].
* **Examples 2.5 (CDFs):**
    * Exponential distribution $T_1 \sim \mathcal{E}xp(q)$: $F_{T_1}(t) = 1 - e^{-qt}$ for $t \ge 0$, and $0$ for $t < 0$[cite: 118].
    * Discrete RV taking values $\{1,2,3\}$ with equal probability: $F_X(x)$ is a step function[cite: 118].
* **Definition 2.6 (Discrete Random Variable):** Takes values in a countable set $X(\Omega)$. Has a probability mass function (PMF) $p_X(x) = \mathbb{P}(X=x)$[cite: 119, 120].
    * **Example 2.7:** PMF for the discrete RV in Example 2.5(ii)[cite: 121].
* **Definition 2.8 (Continuous Random Variable):** Has a probability density function (PDF) $f_X(x)$ such that $\mathbb{P}(a < X \le b) = \int_a^b f_X(x)dx$[cite: 121].
    * **Example 2.9:** PDF for $\mathcal{E}xp(q)$ is $f_{T_1}(t) = qe^{-qt}$ for $t \ge 0$[cite: 122]. Example of a mixed-type RV (neither purely discrete nor continuous)[cite: 123].

* **2.1 Expectation ($\mathbb{E}(X)$)**
    * **Definition 2.10 (Expectation of non-negative discrete $X$):** $\mathbb{E}(X) = \sum_{x \in X(\Omega)} x \mathbb{P}(X=x)$[cite: 124, 125].
        * For an indicator function $1_E$, $\mathbb{E}(1_E) = \mathbb{P}(E)$[cite: 125].
    * **Definition 2.11 (Expectation of general non-negative $X$):** $\mathbb{E}(X) = \sup\{\mathbb{E}(Y) : Y \text{ is discrete and } Y \le X\}$. This is the Lebesgue integral $\int X(\omega) d\mathbb{P}(\omega)$[cite: 126].
        * If $X$ is continuous with PDF $f_X(x)$, $\mathbb{E}(X) = \int_{\mathbb{R}} x f_X(x)dx$[cite: 126].
    * **Lemma 2.12 (Properties of expectation for non-negative RVs):** [cite: 127]
        * Linearity: $\mathbb{E}(\lambda X + \mu Y) = \lambda \mathbb{E}(X) + \mu \mathbb{E}(Y)$ for $\lambda, \mu > 0$[cite: 127].
        * If $\mathbb{P}(X=\infty) > 0$, then $\mathbb{E}(X)=\infty$.
        * If $\mathbb{E}(X) < \infty$, then $\mathbb{P}(X < \infty) = 1$ (X is finite almost surely)[cite: 127, 129].
    * **Theorem 2.13 (Monotone Convergence Theorem, MON):** If $0 \le X_n \uparrow X$ (non-negative RVs, increasing sequence), then $\mathbb{E}(X_n) \uparrow \mathbb{E}(X)$[cite: 130].
        * **Remark 2.14:** MON implies continuity of probability measures[cite: 131, 132].
    * **Fubini-Tonelli-type result:** For non-negative RVs $(X_k)$, $\sum_{k=1}^\infty \mathbb{E}(X_k) = \mathbb{E}(\sum_{k=1}^\infty X_k)$[cite: 133].
    * **Proposition 2.15:** If $X_k \ge 0$: $\sum \mathbb{E}(X_k) < \infty \implies \mathbb{E}(\sum X_k) < \infty \implies \mathbb{P}(\sum X_k < \infty) = 1 \implies \mathbb{P}(X_k \to 0) = 1$[cite: 132, 135].
    * **Lemma 2.16 (First Borel-Cantelli Lemma):** If $\sum_{k=1}^\infty \mathbb{P}(J_k) < \infty$, then $\mathbb{P}(\text{only finitely many } J_k \text{ occur}) = 1$[cite: 137, 138].
        * **Proof Idea:** Use indicator functions $X_k = 1_{J_k}$ and apply Proposition 2.15[cite: 139, 140].

* **2.2 Integrable $X$, $\mathcal{L}^1$**
    * **Idea:** Extend expectation to general RVs (not necessarily non-negative)[cite: 143].
    * **Positive and Negative Parts:** $X^+ = \max\{0, X\}$, $X^- = \max\{0, -X\}$. Then $X = X^+ - X^-$ and $|X| = X^+ + X^-$[cite: 144, 145].
    * **Definition 2.17 (Integrable RV):** $X$ is integrable ($X \in \mathcal{L}^1$) if $\mathbb{E}(|X|) = \mathbb{E}(X^+) + \mathbb{E}(X^-) < \infty$. In this case, $\mathbb{E}(X) = \mathbb{E}(X^+) - \mathbb{E}(X^-)$[cite: 146].
    * **Proposition 2.18 (Properties of expectation for integrable RVs):** [cite: 147]
        * $|\mathbb{E}(X)| \le \mathbb{E}(|X|)$[cite: 147].
        * Linearity: $\mathbb{E}(\lambda X + \mu Y) = \lambda \mathbb{E}(X) + \mu \mathbb{E}(Y)$ for $\lambda, \mu \in \mathbb{R}$[cite: 147].
        * Expectation of $h(X)$:
            * Discrete $X$: $\mathbb{E}(h(X)) = \sum_x h(x) \mathbb{P}(X=x)$[cite: 149].
            * Continuous $X$ with PDF $f_X$: $\mathbb{E}(h(X)) = \int_{\mathbb{R}} h(x) f_X(x)dx$[cite: 150].
    * **Example 2.19:** If $T_1 \sim \mathcal{E}xp(q)$, then $\mathbb{E}(T_1) = 1/q$[cite: 152].
    * **Proof of Inclusion-Exclusion using Expectation:** Using $1_{\cup F_i} = 1 - \prod(1-1_{F_i})$ and linearity of expectation[cite: 153, 155, 156].
    * **Theorem 2.20 (Bounded Convergence Theorem):** If $X_n \to X$ almost surely and $|X_n| \le K$ (uniformly bounded), then $\mathbb{E}(|X_n - X|) \to 0$ and $\mathbb{E}(X_n) \to \mathbb{E}(X)$[cite: 157].

### Chapter 3: Conditional probabilities and independence

* **3.1 Conditional Probabilities**
    * **Definition 3.1:** If $\mathbb{P}(A) > 0$, then $\mathbb{P}(B|A) = \frac{\mathbb{P}(B \cap A)}{\mathbb{P}(A)}$[cite: 161].
        * $\mathbb{P}(\cdot|A)$ is a probability measure[cite: 161].
    * **Multiplication Principle:** $\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B|A)$[cite: 163].
        * **Theorem 3.2 (General Multiplication Principle):** $\mathbb{P}(A_1 \cap \dots \cap A_n) = \mathbb{P}(A_1)\mathbb{P}(A_2|A_1)\dots\mathbb{P}(A_n|A_1 \cap \dots \cap A_{n-1})$[cite: 165, 166].
    * **Law of Total Probability:** If $H_1, \dots, H_n$ partition $\Omega$, then $\mathbb{P}(K) = \sum_{j=1}^n \mathbb{P}(H_j)\mathbb{P}(K|H_j)$[cite: 167, 168].
    * **Theorem 3.3 (Bayes' Theorem):** Formula for $\mathbb{P}(H_i|K)$ using the terms above[cite: 169, 170].

* **3.2 Independence**
    * **Definition (Events $A, B$):** $A, B$ are independent if $\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B)$[cite: 172].
        * If independent, $\mathbb{P}(A|B) = \mathbb{P}(A)$[cite: 172].
    * **Definition 3.4 (Independence of multiple events):**
        * Finite events $E_1, \dots, E_n$: For any subcollection, the probability of their intersection is the product of their probabilities[cite: 174].
        * Infinite events $E_1, E_2, \dots$: Every finite subcollection is independent[cite: 175].
    * **Lemma 3.5 (Second Borel-Cantelli Lemma):** If $J_1, J_2, \dots$ are *independent* events and $\sum \mathbb{P}(J_i) = \infty$, then $\mathbb{P}(\text{infinitely many } J_n \text{ occur}) = 1$[cite: 177, 178].
        * **Proof Idea:** Uses $\mathbb{P}(\cap J_i^c) \le \exp(-\sum \mathbb{P}(J_i))$[cite: 180]. (Note: Proof in notes is stated as "continued on Problem Sheet 2" [cite: 182]).
    * **Definition 3.6 (Independent Random Variables):** $X_1, X_2, \dots$ are independent if for any $x_1, x_2, \dots$, the events $\{X_1 \le x_1\}, \{X_2 \le x_2\}, \dots$ are independent[cite: 183, 184].
    * **Proposition 3.8:** If $X_1, X_2, \dots$ are independent RVs, then $f_1(X_1), f_2(X_2), \dots$ are independent for nice functions $f_i$. Also, $g(X_1, \dots, X_n), X_{n+1}, \dots$ are independent[cite: 185, 186].
    * **Lemma 3.9 (Expectation of Product of Independent RVs):** [cite: 191]
        * If $X, Y \ge 0$ and independent, $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$[cite: 191].
        * If $X, Y \in \mathcal{L}^1$ and independent, then $XY \in \mathcal{L}^1$ and $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$[cite: 192].
    * **Remark 3.10 (Borel measurable function - technical clarification):** A function $f: \mathbb{R}^n \to \mathbb{R}$ is Borel measurable if $f^{-1}(B)$ is a Borel set in $\mathbb{R}^n$ for any Borel set $B \subset \mathbb{R}$[cite: 192, 193, 194].

### Chapter 4: Random Walks

* **Core Idea:** A process that takes steps up or down based on probabilities[cite: 195, 196].
* **Definition (Simple Random Walk $SRW(p)$):** Position at time $n$ is $W_n = a + X_1 + \dots + X_n$, where $W_0=a$ is the start, and $X_i$ are i.i.d. with $\mathbb{P}(X_i = +1) = p$ and $\mathbb{P}(X_i = -1) = q = 1-p$[cite: 200].
    * $\mathbb{P}_a$ denotes probability when starting at $a$[cite: 201].
    * **Markov Property:** The future of the walk given the present state is independent of the past states; it only depends on the current state $W_n$[cite: 202, 203, 204].

* **4.1 Simple Random Walks: Hitting and return probabilities**
    * **Notation:** $H = \{\text{event } W_n = 0 \text{ for some } n \ge 1\}$. $x_i = \mathbb{P}_i(H)$ is the probability of hitting 0 starting from $i$[cite: 206].
    * **Derivation for $x_i$:**
        * Conditioning on the first step: $x_i = p x_{i+1} + q x_{i-1}$ for $i \ge 2$.
        * Special case for $x_1$: $x_1 = p x_2 + q$ (since if it steps to 0, it has hit 0)[cite: 209].
        * Key relation using strong Markov property (intuitively): $x_i = (x_1)^i$ for $i \ge 1$[cite: 210, 211].
        * Solving $x_1 = p x_1^2 + q$ gives $x_1 = 1$ or $x_1 = q/p$[cite: 211].
    * **Theorem 4.1 (Hitting probability of 0):** For $i \ge 1$, $\mathbb{P}_i(\text{hit } 0) = (q/p)^i$ if $q < p$ (drift away from 0), and $1$ if $q \ge p$ (drift towards or no drift)[cite: 213, 214, 215]. By symmetry for $i \le -1$.
    * **Return probability to 0 ($x_0$):** $\mathbb{P}_0(\text{return to } 0) = x_0 = 1 - |p-q|$. So, probability of no return is $|p-q|$[cite: 216].

* **4.2 Gambler's Ruin**
    * **Problem:** Probability $x_k$ that a gambler starting with $£k$ reaches $£N$ before $£0$ (bankruptcy)[cite: 217, 219, 220].
    * **Setup:** $T_j = \inf\{n \ge 0 : W_n = j\}$. We want $x_k = \mathbb{P}_k(T_N < T_0)$[cite: 220].
    * **Recurrence relation:** $x_k = p x_{k+1} + q x_{k-1}$ for $1 \le k \le N-1$, with boundary conditions $x_0 = 0, x_N = 1$[cite: 221].
    * **Theorem 4.2 (Gambler's Ruin Probability):** [cite: 224]
        * If $p \ne q$: $x_k = \frac{1 - (q/p)^k}{1 - (q/p)^N}$.
        * If $p = q = 1/2$: $x_k = k/N$.

* **4.3 Gambler's Ruin - Expected duration of the game**
    * **Notation:** $T = T_0 \wedge T_N = \min\{T_0, T_N\}$. $y_k = \mathbb{E}_k(T)$[cite: 226].
    * **Recurrence relation for $y_k$:** $y_k = 1 + p y_{k+1} + q y_{k-1}$ for $1 \le k \le N-1$, with $y_0 = 0, y_N = 0$[cite: 226, 227]. (Note: page 28 states $y_N=N$ in eq 12, but $y_N=0$ earlier, the context of solving implies $y_N=0$ for the expected time to hit *either* 0 *or* N). The solution provided matches $y_0=0, y_N=0$.
    * **Theorem 4.4 (Expected Duration):** If $p \ne 1/2$, $\mathbb{E}_k(T) = \frac{N x_k - k}{p-q}$ (where $x_k$ is the ruin probability)[cite: 230].
        * The derivation involves solving a non-homogeneous difference equation (see Appendix B for method)[cite: 227].

### Chapter 5: Generating Functions

* **Core Idea:** A tool to analyze distributions of random variables, especially sums of independent RVs and for limit laws[cite: 235, 236].
* **Definition 5.1 (Probability Generating Function, PGF):** For an RV $X$ on $\mathbb{Z}^+ \cup \{\infty\}$, $g_X(\theta) = \mathbb{E}(\theta^X) = \sum_{k=0}^\infty \theta^k \mathbb{P}(X=k)$ for $\theta \in [0,1)$[cite: 237]. Convention $\theta^\infty = 0$ for $\theta < 1$.
* **Examples 5.2 (PGFs):**
    * Bernoulli($p$): $g_X(\theta) = (1-p) + p\theta$[cite: 238].
    * Poisson($\lambda$): $g_Y(\theta) = e^{\lambda(\theta-1)}$[cite: 238].
* **Remark 5.3 & Lemma 5.4 (Properties of PGFs):** [cite: 239, 241]
    * $g_X(1^-) = \lim_{\theta \uparrow 1} g_X(\theta) = \mathbb{P}(X < \infty)$[cite: 239].
    * If $\mathbb{P}(X < \infty) = 1$:
        * $g_X(1) = 1$.
        * $g_X'(1) = \mathbb{E}(X)$.
        * $g_X''(1) = \mathbb{E}(X(X-1))$ (factorial moment).
        * $g_X^{(k)}(1) = \mathbb{E}(X(X-1)\dots(X-k+1))$[cite: 241].
    * $\mathbb{P}(X=k) = \frac{g_X^{(k)}(0)}{k!}$ (PGF uniquely determines distribution)[cite: 246].
* **Theorem 5.5 (PGF of a Sum of Independent RVs):** If $X, Y$ are independent, then $g_{X+Y}(\theta) = g_X(\theta)g_Y(\theta)$[cite: 243].
    * **Proof:** $\mathbb{E}(\theta^{X+Y}) = \mathbb{E}(\theta^X \theta^Y) = \mathbb{E}(\theta^X)\mathbb{E}(\theta^Y)$ by independence[cite: 244].
* **Examples 5.6:**
    * Binomial($n,p$) as sum of $n$ i.i.d. Bernoulli($p$): $g_{X_n}(\theta) = ( (1-p) + p\theta )^n$[cite: 245].
    * Sum of independent Poissons: If $X \sim Po(\lambda), Y \sim Po(\mu)$ are independent, $X+Y \sim Po(\lambda+\mu)$ because $g_{X+Y}(\theta) = e^{(\lambda+\mu)(\theta-1)}$[cite: 245].
* **Theorem 5.7 (Uniqueness):** The PGF uniquely determines the distribution[cite: 246]. If $g_Z(\theta) = \sum p_i \theta^i$, then $\mathbb{P}(Z=i) = p_i$[cite: 247].
* **Theorem 5.8 (Convergence of PGFs):** $X_n \xrightarrow{d} X$ (converges in distribution) if and only if $g_{X_n}(\theta) \to g_X(\theta)$ for all $\theta \in [0,1)$. Convergence in distribution here means $\mathbb{P}(X_n=k) \to \mathbb{P}(X=k)$ for all $k \ge 0$ for $\mathbb{Z}^+$-valued RVs[cite: 250, 251, 252].
* **Example 5.9 (Poisson Approximation of Binomial):** If $X_n \sim B(n, p_n)$ with $p_n = \lambda/n$, then $g_{X_n}(\theta) \to e^{\lambda(\theta-1)}$ (PGF of $Po(\lambda)$), so $X_n \xrightarrow{d} Po(\lambda)$[cite: 253, 254].

### Chapter 6: More on random walks

* **6.1 Distribution of the return time for a simple random walk**
    * **Notation:** $H_r = \inf\{k > 0 : W_k = r\}$ (first return/hitting time of $r$, starting from 0). $g_r(\theta) = \mathbb{E}_0(\theta^{H_r})$[cite: 259].
    * **Theorem 6.1:** [cite: 260]
        * $g_r(\theta) = (g_1(\theta))^r$ for $r > 0$.
        * $g_1(\theta) = \frac{1 - \sqrt{1 - 4pq\theta^2}}{2q\theta}$.
        * $g_0(\theta) = 1 - \sqrt{1 - 4pq\theta^2}$ (PGF of first return time to origin).
        * $\mathbb{P}_0(H_0 = \infty) = |p-q|$ (probability of no return)[cite: 261].
        * $\mathbb{P}_0(H_0 = 2n) = \frac{1}{2n-1}\binom{2n}{n}p^n q^n$ for $n \ge 1$[cite: 261]. (Return can only happen at even times).
        * If $p=q=1/2$, $\mathbb{P}_0(H_0 < \infty) = 1$ but $\mathbb{E}_0(H_0) = \infty$ (recurrent null)[cite: 261].
    * **Proof Idea for $g_1(\theta)$:** Condition on the first step and use $g_2(\theta) = (g_1(\theta))^2$ to form a quadratic equation for $g_1(\theta)$[cite: 264].
    * **Proof Idea for $\mathbb{P}_0(H_0 = 2n)$:** Series expansion of $g_0(\theta)$[cite: 269].

* **6.2 The Reflection Principle**
    * **Idea:** A combinatorial tool for counting paths of a random walk.
    * **Number of paths from $(m,x)$ to $(n,y)$:** $\binom{n-m}{u}$ where $u = \frac{(n-m) + (y-x)}{2}$ is the number of up-steps[cite: 270, 271, 272].
        * **Remark 6.2:** $n-m$ and $y-x$ must have the same parity[cite: 273].
    * **Corollary 6.3:** For $SRW(p)$ starting at 0, $\mathbb{P}_0(W_n = k)$ involves $p^u q^{n-u}$ times the number of paths. $W_n$ can only be at positions $\{-n, -n+2, \dots, n\}$[cite: 275].
    * **Theorem 6.4 (Reflection Principle for Paths):** For $x, y > 0$, the number of paths from $(m,x)$ to $(n,y)$ that touch or cross the time axis (level 0) equals the number of paths from $(m,x)$ to $(n,-y)$, which also equals the number of paths from $(m,-x)$ to $(n,y)$[cite: 277].
        * **Proof Idea:** Reflect the portion of the path after its first hit of the axis[cite: 278, 279].
    * **Theorem 6.5 (Reflection Principle for Symmetric SRW, $p=1/2$):** If $M_n = \max_{k \le n} W_k$, then for $m > 0$, $\mathbb{P}_0(M_n \ge m, W_n = m-k) = \mathbb{P}_0(W_n = m+k)$ for $k \ge 0$[cite: 280].
    * **Theorem 6.6 (Ballot Theorem):** In an election where candidate A gets $a$ votes and B gets $b$ votes ($a > b$), if slips are counted in random order, the probability that A is strictly in the lead throughout the count is $\frac{a-b}{a+b}$[cite: 283, 284].
        * **Proof Idea:** Relate to paths from $(0,0)$ to $(a+b, a-b)$. Path must go to $(1,1)$ first and then avoid hitting 0. Use reflection principle to count paths from $(1,1)$ that hit 0 before reaching $(a+b, a-b)$[cite: 285, 286, 287, 288].
    * **Corollary 6.7:** For $SRW(p)$, $\mathbb{P}_0(W_k \ne 0, 1 \le k \le 2n-1 | W_{2n-1}=1) = \frac{1}{2n-1}$[cite: 289].
    * **Theorem 6.8 (Application to return times):** Alternative derivation of $\mathbb{P}_0(H_0 = 2n)$ using Ballot Theorem/Reflection Principle[cite: 292].

### Chapter 7: Modes of Convergence

* **Core Idea:** Different ways to interpret $X_n \to X$ for a sequence of random variables[cite: 295].
* **Definition 7.1 (Modes of Convergence):** [cite: 296]
    * **(i) Almost Surely ($X_n \xrightarrow{a.s.} X$):** $\mathbb{P}(\{\omega : X_n(\omega) \to X(\omega)\}) = 1$[cite: 297].
    * **(ii) In $p$-th mean ($X_n \xrightarrow{\mathcal{L}^p} X$):** $\mathbb{E}(|X_n - X|^p) \to 0$ for $p \ge 1$[cite: 297].
    * **(iii) In Probability ($X_n \xrightarrow{prob.} X$):** For all $\epsilon > 0$, $\mathbb{P}(|X_n - X| > \epsilon) \to 0$[cite: 297].
    * **(iv) In Distribution ($X_n \xrightarrow{(d)} X$ or $X_n \xrightarrow{Law} X$):** $\mathbb{P}(X_n \le x) \to \mathbb{P}(X \le x)$ (i.e., $F_{X_n}(x) \to F_X(x)$) for all points $x$ where $F_X(x)$ is continuous[cite: 297].
* **Remark 7.2:** First three require RVs on same probability space; convergence in distribution does not[cite: 298, 299].
* **Theorem 7.3 (Implications):** [cite: 301, 302, 303]
    * $X_n \xrightarrow{a.s.} X \implies X_n \xrightarrow{prob.} X$.
    * $X_n \xrightarrow{\mathcal{L}^p} X \implies X_n \xrightarrow{prob.} X$.
    * $X_n \xrightarrow{prob.} X \implies X_n \xrightarrow{(d)} X$.
    * If $p > q \ge 1$, $X_n \xrightarrow{\mathcal{L}^p} X \implies X_n \xrightarrow{\mathcal{L}^q} X$.
    * Other implications do not hold in general.
* **Theorem 7.4 (Converse Implications in Special Cases):** [cite: 309]
    * If $X_n \xrightarrow{(d)} c$ (constant), then $X_n \xrightarrow{prob.} c$[cite: 310].
    * If $X_n \xrightarrow{prob.} X$ and $|X_n| \le K$ (uniformly bounded), then $X_n \xrightarrow{\mathcal{L}^p} X$ for all $p \ge 1$[cite: 310].
    * If $\sum_{n=1}^\infty \mathbb{P}(|X_n - X| > \epsilon) < \infty$ for all $\epsilon > 0$, then $X_n \xrightarrow{a.s.} X$ (related to Borel-Cantelli)[cite: 310].
* **Theorem 7.5 (Slutsky's Theorem):** If $X_n \xrightarrow{(d)} X$ and $Y_n \xrightarrow{prob.} c$ (constant), then: [cite: 317]
    1.  $X_n + Y_n \xrightarrow{(d)} X+c$[cite: 317].
    2.  $X_n Y_n \xrightarrow{(d)} Xc$[cite: 318].
* **Remark 7.6:** If $X_n \xrightarrow{(d)} X$ and $Y_n \xrightarrow{(d)} Y$, we cannot generally say anything about $X_n+Y_n$ without knowing about their joint law or independence[cite: 329, 330, 331, 332].

### Chapter 8: Weak and Strong Laws

* **Core Idea (Law of Large Numbers):** The sample mean $\frac{1}{n}\sum_{i=1}^n X_i$ converges to the population mean $\mu = \mathbb{E}(X_1)$ for i.i.d. RVs[cite: 334, 335].
* **Lemma 8.1 (Chebyshev's Inequality):** If $X \in \mathcal{L}^2$ (i.e., $\mathbb{E}(X^2) < \infty$), then $\mathbb{P}(|X - \mathbb{E}(X)| \ge c) \le \frac{Var(X)}{c^2}$ for $c > 0$[cite: 338, 339].
* **Theorem 8.3 (Weak Law of Large Numbers, WLLN):** If $X_i$ are i.i.d. with $\mathbb{E}(X_1^2) < \infty$ (finite variance) and mean $\mu$, then $\frac{1}{n}\sum X_i \xrightarrow{prob.} \mu$[cite: 342, 343, 344].
    * **Proof Idea:** Apply Chebyshev's inequality to $S_n/n = (\sum X_i)/n$. $\mathbb{E}(S_n/n) = \mu$, $Var(S_n/n) = Var(X_1)/n \to 0$[cite: 347].
    * **Remark 8.4:** Conditions are not optimal; WLLN holds if and only if weaker conditions on tails or characteristic function are met[cite: 345, 346].
* **Theorem 8.5 (Strong Law of Large Numbers, SLLN):** If $X_i$ are i.i.d., then $\frac{1}{n}\sum X_i \xrightarrow{a.s.} \mu$ for some constant $\mu$ if and only if $\mathbb{E}(|X_1|) < \infty$ (finite mean). In this case, $\mu = \mathbb{E}(X_1)$[cite: 348, 349].
    * **Proof Sketch (special case $\mathbb{E}(X_1^2) < \infty$):** Show convergence along subsequence $n_k = k^2$ using Chebyshev and Borel-Cantelli. Then "fill the gaps"[cite: 351, 352, 353, 354, 355, 356, 357]. Decompose $X_i = X_i^+ - X_i^-$ for general case[cite: 357, 358].
* **Remark 8.6 & 8.7 (Discussion SLLN vs WLLN):** SLLN is stronger. WLLN means for a given large $n$, the sample mean is likely close to $\mu$. SLLN means the sample mean *path* converges to $\mu$ with probability 1[cite: 359, 360, 361, 362, 363, 367, 368, 369, 370]. WLLN can hold even if SLLN doesn't (if $\mathbb{E}|X_1| = \infty$ but other conditions met)[cite: 364, 365, 366, 371, 372, 373].

### Chapter 9: Conditional Expectation

* **9.1 Discrete Random Variables**
    * **Recall:** $\mathbb{E}(X|A) = \frac{\mathbb{E}(X 1_A)}{\mathbb{P}(A)}$ for an event $A$[cite: 375]. This is $\sum_j x_j \mathbb{P}(X=x_j | A)$[cite: 375, 376].
    * **Definition 9.1 (Conditional Expectation given a discrete RV $Y$):** $\mathbb{E}(X|Y) := \sum_{j} 1_{\{Y=y_j\}} \mathbb{E}(X|Y=y_j)$[cite: 377, 378].
    * **Remark 9.2:** $\mathbb{E}(X|Y=y_j)$ is a number; $\mathbb{E}(X|Y)$ is a random variable, and it's a function of $Y$. (i.e., $\mathbb{E}(X|Y) = f(Y)$ where $f(y) = \mathbb{E}(X|Y=y)$)[cite: 379, 380, 381, 382].
    * **Example 9.3:** $Y \sim Po(\lambda)$ alerts. Each leaks with probability $p$. $Z=$ number of leaks.
        * $\mathbb{E}(Z|Y=n) = np$ (since $Z|Y=n \sim B(n,p)$)[cite: 383, 384, 385, 386, 387, 388].
        * $\mathbb{E}(Z|Y) = pY$ (a random variable)[cite: 389, 390].
    * **Lemma 9.4 (The Tower Property / Law of Total Expectation):** $\mathbb{E}(\mathbb{E}(X|Y)) = \mathbb{E}(X)$[cite: 391].
        * **Proof Idea:** Expand $\mathbb{E}(\mathbb{E}(X|Y))$ using the definition and sum over values of $Y$[cite: 392].
    * **Example 9.5:** Finding distribution of $Z$ (leaks) using PGFs and tower property. $g_Z(s) = \mathbb{E}(s^Z) = \mathbb{E}(\mathbb{E}(s^Z|Y))$. Since $Z|Y=n \sim B(n,p)$, $\mathbb{E}(s^Z|Y=n) = (ps+q)^n$. So $\mathbb{E}(s^Z|Y) = (ps+q)^Y$. Then $\mathbb{E}((ps+q)^Y) = g_Y(ps+q) = e^{\lambda((ps+q)-1)} = e^{\lambda p (s-1)}$. This is PGF of $Po(\lambda p)$, so $Z \sim Po(\lambda p)$[cite: 393, 394, 395, 396, 397].
    * **Lemma 9.6 (Other key properties for discrete RVs):** [cite: 398]
        * Taking out what is known: $\mathbb{E}(h(Y)X | Y) = h(Y)\mathbb{E}(X|Y)$[cite: 398].
        * Independence: If $X, Y$ independent, $\mathbb{E}(X|Y) = \mathbb{E}(X)$[cite: 399].
        * Linearity: $\mathbb{E}(\lambda X + \mu Z | Y) = \lambda \mathbb{E}(X|Y) + \mu \mathbb{E}(Z|Y)$[cite: 400].

* **9.2 Continuous Random Variables**
    * **Joint PDF $f_{X,Y}(x,y)$:** $\mathbb{P}((X,Y) \in A) = \iint_A f_{X,Y}(x,y) dx dy$[cite: 405].
    * **Marginal PDF $f_X(x) = \int f_{X,Y}(x,y) dy$**[cite: 406].
    * **Definition 9.7 (Conditional PDF):** $f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$ for $f_Y(y)>0$[cite: 407].
    * **Conditional CDF $F_{X|Y}(x|y) = \int_{-\infty}^x f_{X|Y}(u|y) du = \mathbb{P}(X \le x | Y=y)$**[cite: 408].
    * **Definition (Conditional Expectation for continuous RVs):** Let $\Psi(y) = \mathbb{E}(X|Y=y) = \int x f_{X|Y}(x|y) dx$. Then $\mathbb{E}(X|Y) = \Psi(Y)$ (a random variable, function of $Y$)[cite: 408, 410].
    * **Properties:** Tower property and other key properties from Lemma 9.6 hold for continuous case too[cite: 411]. Proof of tower property: $\mathbb{E}(\Psi(Y)) = \int \Psi(y) f_Y(y) dy = \dots = \mathbb{E}(X)$[cite: 412].
    * **Example 9.8:** $f_{X,Y}(x,y) = 1/y$ for $0 \le x \le y \le 1$.
        * $f_Y(y) = 1$ for $y \in [0,1]$ ($Y \sim U[0,1]$)[cite: 414, 415].
        * $f_{X|Y}(x|y) = 1/y$ for $0 \le x \le y$ (Given $Y=y$, $X \sim U[0,y]$)[cite: 416].
        * $\mathbb{E}(X|Y=y) = y/2$. So $\mathbb{E}(X|Y) = Y/2$[cite: 417].

### Chapter 10: Branching Processes

* **10.1 The Model**
    * **Idea:** Models evolution of a population (e.g., bacteria)[cite: 419]. Each individual lives one time unit, then replaced by a random number of descendants[cite: 420].
    * Offspring distribution: $\mathbb{P}(X=k) = p_k$, where $X$ is number of descendants of one individual. $X_i^{(n)}$ are i.i.d. copies of $X$[cite: 421, 422, 423].
    * $Z_n$: number of individuals in generation $n$. $Z_0=1$ (usually)[cite: 425].
    * $Z_{n+1} = \sum_{i=1}^{Z_n} X_i^{(n+1)}$[cite: 425].
    * Assume mean offspring $\mu = \mathbb{E}(X) < \infty$[cite: 426].

* **10.2 Average Size of the Population**
    * $\mathbb{E}(Z_{n+1}|Z_n=r) = \mathbb{E}(\sum_{i=1}^r X_i^{(n+1)}) = r\mu$[cite: 429, 430, 431].
    * So $\mathbb{E}(Z_{n+1}|Z_n) = \mu Z_n$[cite: 432].
    * By Tower Property: $\mathbb{E}(Z_{n+1}) = \mathbb{E}(\mathbb{E}(Z_{n+1}|Z_n)) = \mathbb{E}(\mu Z_n) = \mu \mathbb{E}(Z_n)$[cite: 432].
    * **Proposition 10.1:** $\mathbb{E}(Z_n) = \mu^n$ (since $Z_0=1$)[cite: 433, 434].
        * If $\mu > 1, \mathbb{E}(Z_n) \to \infty$. If $\mu < 1, \mathbb{E}(Z_n) \to 0$. If $\mu = 1, \mathbb{E}(Z_n) = 1$[cite: 434].

* **10.3 Extinction probability of the population**
    * **Notation:** $\pi = \mathbb{P}(\text{ultimate extinction}) = \mathbb{P}(Z_n = 0 \text{ for some } n)$[cite: 434].
    * Assume $p_0 = \mathbb{P}(X=0) > 0$ (otherwise $\pi=0$)[cite: 435].
    * $\pi_n = \mathbb{P}(Z_n=0)$ (extinction by time $n$).
    * **Lemma 10.2:** $\pi_n \uparrow \pi$. And $\pi_{n+1} = g(\pi_n)$, where $g(\theta) = \mathbb{E}(\theta^X)$ is the PGF of the offspring distribution $X$[cite: 437].
        * **Proof Idea for $\pi_{n+1}=g(\pi_n)$:** $\mathbb{P}(Z_{n+1}=0) = \sum_k \mathbb{P}(Z_1=k) \mathbb{P}(Z_{n+1}=0|Z_1=k)$. If $Z_1=k$, then for $Z_{n+1}$ to be 0, all $k$ independent sub-processes must die out by (further) $n$ generations. The probability for one sub-process to die out by generation $n$ (starting from one ancestor) is $\pi_n$. So $\mathbb{P}(Z_{n+1}=0|Z_1=k) = (\pi_n)^k$. Thus $\pi_{n+1} = \sum_k p_k (\pi_n)^k = g(\pi_n)$[cite: 439, 440, 441].
    * **Theorem 10.3 (Extinction Probability $\pi$):** $\pi$ is a fixed point of $g$, i.e., $g(\pi)=\pi$.
        * (i) If $\mu = \mathbb{E}(X) \le 1$, then $\pi=1$ (extinction is certain), unless $p_1=1$ (trivial case)[cite: 444].
        * (ii) If $\mu > 1$, then $\pi$ is the unique root of $g(s)=s$ in the interval $[0,1)$[cite: 445].
    * **Proof Idea:** $g(s)$ is convex, $g(1)=1$, $g'(1)=\mu$.
        * If $\mu \le 1$: The graph of $g(s)$ is above $s=s$ for $s \in [0,1)$ until $s=1$. So $s=1$ is the only solution in $[0,1]$[cite: 448, 449, 450, 453, 454, 455, 456].
        * If $\mu > 1$: $g'(1)=\mu > 1$. Since $g(0)=p_0 \ge 0$ and $g(s)$ is convex, there must be exactly one root $\pi_\infty \in [0,1)$ besides $s=1$. Since $\pi_n \uparrow \pi$ and $\pi_{n+1}=g(\pi_n)$, and $\pi_1=p_0 \le \pi_\infty$, it implies $\pi_n \le \pi_\infty$ for all $n$, so $\pi \le \pi_\infty$. Since $\pi$ is a fixed point, $\pi = \pi_\infty$[cite: 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466].

### Chapter 11: Poisson Processes

* **Core Idea:** Models random occurrences of events in time (or space)[cite: 467].
* **11.1 Poisson Point Processes on $[0, \infty)$ (PP($\lambda$))**
    * **Definition 11.1 (Counting definition):** $N(A)$ is number of arrivals in interval $A$.
        1.  Numbers of arrivals $N(A_1), \dots, N(A_n)$ in disjoint time intervals $A_i$ are independent RVs[cite: 470].
        2.  Number of arrivals $N(A)$ in an interval $A$ of length $t$ has $Po(\lambda t)$ distribution[cite: 470, 471].
    * **Lemma 11.2 (Inter-arrival time definition):** Equivalent description. Inter-arrival times $\xi_1, \xi_2, \dots$ are i.i.d. Exponential($\lambda$) RVs. Arrival times $T_n = \sum_{k=1}^n \xi_k$[cite: 471, 472, 473].
        * Connection: If $N(0,t] \sim Po(\lambda t)$, then $\mathbb{P}(\xi_1 > t) = \mathbb{P}(N(0,t]=0) = e^{-\lambda t}$, so $\xi_1 \sim Exp(\lambda)$[cite: 474]. Memoryless property of Exponential is key for independence of increments.

* **11.2 Decomposing a Poisson Process**
    * **Lemma 11.3 ('Boys and Girls' principle / Thinning):** Two models are equivalent:
        1.  Total births $N \sim Po(\gamma)$. Each birth is boy with prob $p$, girl with prob $q=1-p$, independently.
        2.  Number of boys $B \sim Po(\gamma p)$, number of girls $G \sim Po(\gamma q)$, and $B, G$ are independent[cite: 474, 475].
        * **Proof Idea (ii) $\implies$ (i):** If $B \sim Po(\gamma p), G \sim Po(\gamma q)$ indep., then $B+G \sim Po(\gamma(p+q)) = Po(\gamma)$. Conditional distribution $\mathbb{P}(B=b | B+G=n)$ is $B(n,p)$[cite: 476, 477, 478].
    * **Proposition 11.4 (Decomposition for Poisson Processes):** Two models are equivalent:
        1.  Men arrive as $PP(\lambda)$, women as $PP(\mu)$, independent.
        2.  People arrive as $PP(\lambda+\mu)$. Each person is man with prob $\frac{\lambda}{\lambda+\mu}$, woman with prob $\frac{\mu}{\lambda+\mu}$, independently[cite: 485, 486].

* **11.3 Conditional Uniformity**
    * **Theorem 11.5:** Given $N(0,t]=n$ (i.e., $n$ arrivals in $(0,t]$ for a $PP(\lambda)$), the $n$ arrival times are distributed as $n$ i.i.d. Uniform$(0,t)$ RVs[cite: 488, 489].
        * **Proof Idea:** Discretize $(0,t]$ into $m$ small intervals $J_r$. Compare probability from multinomial distribution (for $n$ uniforms falling into these bins) with the conditional probability from Poisson process definition. They match[cite: 489, 490, 491, 492, 493, 494].

* **11.4 Poisson point processes on $\mathbb{R}^n$ (PPP($\lambda(\cdot)$))**
    * **Definition 11.6:** Generalization to higher dimensions with a (possibly non-constant) intensity function $\lambda(x)$ on a region $G \subseteq \mathbb{R}^n$[cite: 494, 495].
        1.  $N(G_1), N(G_2), \dots$ for disjoint $G_i \subset G$ are independent.
        2.  $N(G_1) \sim Po(\int_{G_1} \lambda(x) dx)$[cite: 495, 496].
    * **Remark 11.7:**
        * Recovers classical $PP(\lambda)$ if $n=1, G=[0,\infty), \lambda(x)=\lambda$ constant[cite: 497].
        * $\mathbb{E}(N(G_1)) = \int_{G_1} \lambda(x) dx$[cite: 498, 499].
    * **Example 11.8:** PPP on $\mathbb{R}$ with $\lambda(x) = e^{-\mu|x|}$. Total points $N(\mathbb{R}) \sim Po(2/\mu)$[cite: 500, 501, 502].
    * **Proposition 11.9 (Conditional Uniformity on $G$):** If $\lambda(x)=\lambda$ is constant on $V \subseteq G$, then given $N(V)=n$, the $n$ points are i.i.d. Uniform in $V$[cite: 503].
    * **Example 11.10 (Raindrops):** PPP on $\mathbb{R}^+ \times \mathbb{R}$ (time-space) with constant rate $\lambda$.
        * $N((s,s+t] \times [x,x+y]) \sim Po(\lambda \cdot t \cdot y)$[cite: 505, 506].
        * Distribution of first time a raindrop falls in $[0,x]$ is $Exp(\lambda x)$[cite: 506].
        * Given $n$ raindrops in $[0,x]$ by time $t$, distribution of first arrival time $U$ in that box: $F_U(s|N=n) = 1 - (\frac{t-s}{t})^n$ for $s \in [0,t]$[cite: 508, 509].
        * Distribution of closest raindrop to origin by time $t$: $D_t \sim Exp(2\lambda t)$ (considering interval $[-x,x]$)[cite: 509].

### Chapter 12: The central limit theorem - Lindeberg's proof

* **Core Idea:** Justifies why Normal (Gaussian) distribution is so important. Normalized sums of i.i.d. RVs converge in distribution to a Normal distribution[cite: 510, 511, 512, 513].
* **Theorem 12.1 (Central Limit Theorem, CLT):** Let $X_i$ be i.i.d. with $\mathbb{E}(X_1)=\mu$ and $Var(X_1)=\sigma^2 < \infty$. Let $S_n = \sum_{i=1}^n X_i$. Then $\frac{S_n - n\mu}{\sqrt{n\sigma^2}} \xrightarrow{(d)} Z$, where $Z \sim N(0,1)$ (standard Normal)[cite: 517, 518, 519, 520].
* **Remark 12.2 (Lindeberg Condition):** A more general condition for CLT to hold for sums of independent (not necessarily identically distributed) RVs. Requires that individual variances are small compared to the total sum of variances in a specific limiting sense ($L_n(\epsilon) \to 0$)[cite: 521, 522, 523, 524, 525, 526].
* **Lindeberg's Proof Strategy (for i.i.d. case, Theorem 12.1):**
    * Assume $\mu=0$ WLOG[cite: 534].
    * **Idea:** Replace $X_i$ one by one with independent Normal RVs $V_i \sim N(0, \sigma^2)$ and show the accumulated difference in expectation of a smooth function $f$ is small[cite: 527, 528, 529, 530, 531, 532].
    * **Proposition 12.3:** For $f$ bounded with 3 bounded continuous derivatives, $\mathbb{E}(f(\frac{S_n}{\sqrt{n\sigma^2}})) \to \mathbb{E}(f(Z))$[cite: 535, 536, 537].
    * **Proposition 12.4:** If Prop 12.3 holds, then CLT (convergence of CDFs) holds[cite: 537].
* **12.1 Proof of Proposition 12.4 (Sketch):**
    * Approximate indicator function $1_{(-\infty, a]}(x)$ by smooth functions $f_{a,\delta}(x)$ for which Prop 12.3 applies.
    * Use $f_{a,\delta}(x+\delta) \le 1_{(-\infty, a]}(x) \le f_{a,\delta}(x)$ and take limits as $n \to \infty$ and then $\delta \to 0$ using Dominated Convergence Theorem[cite: 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550].
* **12.2 Proof of Proposition 12.3 (Sketch):**
    * Let $V_i \sim N(0,\sigma^2)$ be i.i.d. and independent of $X_i$.
    * Define $Y_i = \frac{V_1+\dots+V_{i-1}+X_{i+1}+\dots+X_n}{\sqrt{n\sigma^2}}$, $\Delta_{X,i} = \frac{X_i}{\sqrt{n\sigma^2}}$, $\Delta_{V,i} = \frac{V_i}{\sqrt{n\sigma^2}}$[cite: 559].
    * $\mathbb{E}(f(Z)) - \mathbb{E}(f(\frac{S_n}{\sqrt{n\sigma^2}})) = \sum_{i=1}^n (\mathbb{E}(f(Y_i+\Delta_{V,i})) - \mathbb{E}(f(Y_i+\Delta_{X,i})))$ (telescoping sum trick)[cite: 556, 557, 558, 560, 561, 563].
    * Use Taylor expansion for $f$ up to 2nd order with a remainder term: $f(x+\delta) = f(x) + \delta f'(x) + \frac{\delta^2}{2}f''(x) + \delta^2 R(x,\delta)$[cite: 564].
    * $\mathbb{E}(\Delta_{V,i}) = \mathbb{E}(\Delta_{X,i}) = 0$. $\mathbb{E}(\Delta_{V,i}^2) = \mathbb{E}(\Delta_{X,i}^2) = 1/n$[cite: 562].
    * The terms from $f'(Y_i)$ and $f''(Y_i)$ cancel out in expectation due to independence and matching first two moments of $X_i/\sqrt{n\sigma^2}$ and $V_i/\sqrt{n\sigma^2}$[cite: 569].
    * The difference is bounded by terms involving the remainder $R$. Show that $\mathbb{E}(\Delta_{V,i}^2 |R(Y_i, \Delta_{V,i})|)$ and $\mathbb{E}(\Delta_{X,i}^2 |R(Y_i, \Delta_{X,i})|)$ are $o(1/n)$ (e.g., $\le \epsilon/n$)[cite: 566, 567, 568, 570, 571, 572].
    * Summing $n$ such terms gives a total error of $O(\epsilon)$, which means the limit is 0[cite: 574, 575, 576, 577].

### Appendices

* **A Important distributions:** Table of PMF/PDF, E(X), Var(X), PGF for Bernoulli, Binomial, Poisson, Geometric, Exponential, Uniform, Normal[cite: 579, 580, 581, 582, 583].
* **B Solving difference equation (or recurrence equations):** Method to solve $x_{n+2} + ax_{n+1} + bx_n = \gamma$.
    1.  Find general solution $y_n$ to homogeneous equation (auxiliary equation $\lambda^2+a\lambda+b=0$).
        * Distinct roots $\lambda_1, \lambda_2 \implies y_n = A\lambda_1^n + B\lambda_2^n$.
        * Repeated root $\lambda_1 \implies y_n = (A+Bn)\lambda_1^n$.
    2.  Find a particular solution $z_n$ to the inhomogeneous equation (trial and error, e.g., try $z_n=$ constant, or $z_n=cn$).
    3.  General solution $x_n = y_n + z_n$. Use boundary conditions to find constants $A, B$[cite: 584, 586, 587, 589, 590, 591, 592, 595, 596, 599, 601, 602, 603].
    * Brief mention of higher-order equations[cite: 607, 608, 609, 610, 611, 612, 613, 614].
* **C Analysis handout:** List of facts:
    * Convergence of $\sum 1/(a+n)^p \iff p > 1$[cite: 617].
    * Convergence of $\int^\infty 1/y^p dy \iff p > 1$[cite: 619].
    * Taylor expansion $f(x) = \sum f^{(n)}(a)/n! \cdot (x-a)^n$ (mistake in notes, should be $(x-a)^n$)[cite: 619, 620].

This covers the main topics from your lecture notes. Let me know if you'd like a deeper dive into any specific section!
